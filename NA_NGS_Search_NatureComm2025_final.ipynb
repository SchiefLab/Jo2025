{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T23:08:08.178996Z",
     "iopub.status.busy": "2023-06-20T23:08:08.178684Z",
     "iopub.status.idle": "2023-06-20T23:09:15.768849Z",
     "shell.execute_reply": "2023-06-20T23:09:15.768121Z",
     "shell.execute_reply.started": "2023-06-20T23:08:08.178971Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "import tempfile\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import subprocess\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\"\"\"\n",
    "Import Parquet As a DataFrame\n",
    "\"\"\"\n",
    "\n",
    "##Read in parquet file from public S3 bucket\n",
    "parquet_s3 = \"s3://steichenetalpublicdata/analyzed_sequences/parquet\"\n",
    "df_spark = spark.read.parquet(parquet_s3)\n",
    "\n",
    "##Verify count \n",
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a query class\n",
    "The query class can hold our spark query until it's time to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T23:09:45.743489Z",
     "iopub.status.busy": "2023-06-20T23:09:45.743160Z",
     "iopub.status.idle": "2023-06-20T23:12:43.771692Z",
     "shell.execute_reply": "2023-06-20T23:12:43.770801Z",
     "shell.execute_reply.started": "2023-06-20T23:09:45.743455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Query():\n",
    "    \n",
    "    '''An example query class to hold query parameters'''\n",
    "    \n",
    "    def __init__(self,q_name,length_min='',length_max='',v_fam=\"\",v_gene=\"\",d_gene=\"\",j_gene=\"\",regex=\"\",ez_donor=\"\"):\n",
    "        self.query_name = q_name\n",
    "        self.v_fam = v_fam\n",
    "        self.v_gene = v_gene\n",
    "        self.j_gene = j_gene\n",
    "        self.d_gene = d_gene\n",
    "        self.ez_donor = ez_donor\n",
    "        \n",
    "        if not length_min:\n",
    "            raise Exception(\"Minimum length must be supplied\")\n",
    "        self.length_min = length_min\n",
    "        self.length_max = length_max\n",
    "        self.regular_expression = regex\n",
    "    \n",
    "    \n",
    "    \n",
    "    def apply(self,df):\n",
    "        \n",
    "        '''Apply function will take in spark dataframe and apply query parameters to it if they exist\n",
    "        \n",
    "           Returns a filtered dataframe\n",
    "        '''\n",
    "        self.queried_dataframe = \"\"\n",
    "        \n",
    "        ##Lets get length\n",
    "        \n",
    "        self.queried_dataframe = df.filter(F.length(df.cdr3_aa) > self.length_min)\n",
    "        self.queried_dataframe = df.filter(F.length(df.cdr3_aa) < self.length_max)\n",
    "        \n",
    "        ##If the rest of these were specified, add them to the filter\n",
    "        if self.v_fam:\n",
    "            self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.v_fam == self.v_fam)\n",
    "        \n",
    "        if self.v_gene:\n",
    "            self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.v_gene == self.v_gene)\n",
    "     \n",
    "        if self.d_gene:\n",
    "            self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.d_gene == self.d_gene)       \n",
    "        \n",
    "        if self.j_gene:\n",
    "            self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.j_gene == self.j_gene)       \n",
    "        \n",
    "\n",
    "        if self.regular_expression:\n",
    "             self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.cdr3_aa.rlike(self.regular_expression))\n",
    "        \n",
    "        if self.ez_donor:\n",
    "             self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.ez_donor == self.ez_donor)\n",
    "            \n",
    "        print(\"Found {} sequences\".format(self.queried_dataframe.count()))\n",
    "        return self.queried_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 1: BCRs have a DR motif at the middle of the 19 - 30 aa HCDR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_1 = Query('DR',length_min=18,length_max=31,regex=r'........DR........$')\n",
    "queried1_df = my_query_1.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas1_df = queried1_df.select('_id','ez_donor','d_gene').toPandas()\n",
    "counts = pandas1_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 2: BCRs have a RD motif at the middle of the 19 - 30 aa HCDR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_2 = Query('RD',length_min=18,length_max=31,regex=r'........RD........$')\n",
    "queried2_df = my_query_2.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas2_df = queried2_df.select('_id','ez_donor','d_gene').toPandas()\n",
    "counts = pandas2_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 3: Precursors use same D genes in the same reading frame, match the regular expression, and contain D genes flanked by an equal or greater number of amino acids compared to DA03E17 BCRs with 19–30 amino acid HCDR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_3 = Query('DA03E17_all',length_min=18,length_max=31, d_gene=\"IGHD3-10\",regex=r'....GSG............')\n",
    "queried3_df = my_query_3.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas3_df = queried3_df.select('_id','ez_donor').toPandas()\n",
    "counts = pandas3_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 4: Precursors met the Frequency 3 criteria, with the DR motif positioned at the same location relative to the D gene as found in DA03E17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_4 = Query('DA03E17_DR',length_min=18,length_max=31, d_gene=\"IGHD3-10\",regex=r'....GSG..DR........')\n",
    "queried4_df = my_query_4.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas4_df = queried4_df.select('_id','ez_donor').toPandas()\n",
    "counts = pandas4_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 5: Precursors use same D genes in the same reading frame, match the regular expression, and contain D genes flanked by an equal or greater number of amino acids compared to 1G05 BCRs with 19–30 amino acid HCDR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_5 = Query('1G05_all',length_min=18,length_max=31, d_gene=\"IGHD5-12\",regex=r'....YSGYD..........')\n",
    "queried5_df = my_query_5.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas5_df = queried5_df.select('_id','ez_donor').toPandas()\n",
    "counts = pandas5_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 6: Precursors met the Frequency 5 criteria, with the DR motif positioned at the same location relative to the D gene as found in 1G05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_6 = Query('1G05_DR',length_min=18,length_max=31, d_gene=\"IGHD5-12\",regex=r'....YSGYDR.........')\n",
    "queried6_df = my_query_6.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas6_df = queried6_df.select('_id','ez_donor').toPandas()\n",
    "counts = pandas6_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 7: Precursors use same D genes in the same reading frame, match the regular expression, and contain D genes flanked by an equal or greater number of amino acids compared to Z2B3 BCRs with 25–30 amino acid HCDR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_7A = Query('DA03E17_all',length_min=24,length_max=31, d_gene=\"IGHD5-18\",regex=r'.....DT.MV...............')\n",
    "my_query_7B = Query('DA03E17_all',length_min=24,length_max=31, d_gene=\"IGHD5-5\",regex=r'.....DT.MV...............')\n",
    "queried7A_df = my_query_7A.apply(df_spark)\n",
    "queried7B_df = my_query_7B.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas7A_df = queried7A_df.select('_id','ez_donor').toPandas()\n",
    "pandas7B_df = queried7B_df.select('_id','ez_donor').toPandas()\n",
    "pandas7_df = pandas.concat([pandas7A_df, pandas7B_df], axis=0)\n",
    "counts = pandas7_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 8: Precursors met the Frequency 7 criteria, with the DR motif positioned at the same location relative to the D gene as found in Z2B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_8A = Query('DA03E17_all',length_min=24,length_max=31, d_gene=\"IGHD5-18\",regex=r'.....DT.MVDR.............')\n",
    "my_query_8B = Query('DA03E17_all',length_min=24,length_max=31, d_gene=\"IGHD5-5\",regex=r'.....DT.MVDR.............')\n",
    "queried8A_df = my_query_8A.apply(df_spark)\n",
    "queried8B_df = my_query_8B.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas8A_df = queried8A_df.select('_id','ez_donor').toPandas()\n",
    "pandas8B_df = queried8B_df.select('_id','ez_donor').toPandas()\n",
    "pandas8_df = pandas.concat([pandas8A_df, pandas8B_df], axis=0)\n",
    "counts = pandas8_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
